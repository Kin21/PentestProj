import time
from pymetasploit3.msfrpc import MsfRpcClient
from bs4 import BeautifulSoup
import pandas as pd
import csv
import json
import requests
import subprocess

from global_data import msfrpc_password



class VulnerabilityMapper:
    def __init__(self):
        # Search vulnerability by cpe
        self.nvd_cpe_api_url = 'https://services.nvd.nist.gov/rest/json/cpes/1.0/'
        self.nvd_cpe_parameters = {'cpeMatchString': None, 'addOns': 'cves', 'resultsPerPage': '100'}
        self.circl_api_url = 'https://cve.circl.lu/api/cvefor/{}'

        # Exploits to CVE map
        self.cve_to_explot_file = 'Exploit_CVE.json'
        self.cve_to_metaslpoit_file = 'cve_to_metasploit.json'
        self.cve_to_metaslpoit_map = self.load_metasploit_map()

    def load_metasploit_map(self):
        try:
            with open(self.cve_to_metaslpoit_file) as f:
                return json.load(f)
        except FileNotFoundError:
            self._map_cve_to_exploit_from_metasploit()
            return self.load_metasploit_map()

    def cpe_to_cve(self, cpe):
        # https://nvd.nist.gov/developers/start-here
        # Rate Limits
        #
        # Requesting an API key allows for users to make a greater number of requests in a given time than they
        # could otherwise. The public rate limit (without an API key) is 10 requests in a rolling 60 second window;
        # the rate limit with an API key is 100 requests in a rolling 60 second window.
        self.nvd_cpe_parameters['cpeMatchString'] = cpe
        data = requests.get(self.nvd_cpe_api_url, params=self.nvd_cpe_parameters)
        try:
            data = data.json()
        except requests.exceptions.JSONDecodeError:
            print('Must sleep for 60 seconds due to API restrictions')
            time.sleep(61)
            return self.cpe_to_cve(cpe)
        possible_vulnerabilities = []
        for res in data['result']['cpes']:
            possible_vulnerabilities += res['vulnerabilities']
        return list(set(possible_vulnerabilities))

    def cve_to_exploits(self, cve):
        with open(self.cve_to_explot_file) as f:
            data = json.load(f)
        exploits = []
        for obj in data:
            if obj['CveId'] == cve:
                exploits.append(obj['ExploitId'])
        return exploits

    def _map_cve_to_exploit_from_metasploit(self):
        global msfrpc_password
        mc = MsfRpcClient(msfrpc_password, port=55553)
        exploits = mc.modules.exploits
        data = {}
        for e in exploits:
            exploit = mc.modules.use('exploit', e)
            ref = exploit.references
            if ref and ref[0][0] == 'CVE':
                linked_cve = '-'.join(ref[0])
                try:
                    existed_exploit = data[linked_cve]
                    existed_exploit.append(e)
                    data.update({linked_cve: existed_exploit})
                except KeyError:
                    data.update({linked_cve: [e]})
        with open(self.cve_to_metaslpoit_file, 'w') as f:
            json.dump(data, f)

    def get_metasploit_exploit_by_cve(self, cve, **search_info):
        try:
            # List of possible operating systems that we are interested in.
            os = search_info['os']
        except KeyError:
            os = None
        try:
            exploits = self.cve_to_metaslpoit_map[cve]
            # If OS is specified, returns only exploit for this OS
            if os:
                exploits = [e for e in exploits if (e.split('/')[0] in os) or (e.split('/')[0] == 'multi')]
            return exploits
        except KeyError:
            return []

    def _update_metasploit(self):
        subprocess.run(['sudo', 'msfupdate'])


    def update(self):
        self.collect_exploit()
        self._update_metasploit()
        self._map_cve_to_exploit_from_metasploit()

    # Function taken from https://github.com/nthnle/nvd-feeds-collection
    # Maps exploits from exploiDB to CVE numbers
    def collect_exploit(self):
        # print("Collecting CVE reference map for source EXPLOIT-DB")
        csv_file = open('Exploit_CVE.csv', 'w')
        csv_writer = csv.writer(csv_file)
        exploitUrl = 'https://cve.mitre.org/data/refs/refmap/source-EXPLOIT-DB.html'
        req = requests.get(exploitUrl, allow_redirects=True)
        # get status code
        # print("Exploit status code: " + str(req.status_code))
        # read the data from the URL and print it in html form
        # this is the full html, not just the table's html
        # we will need to parse through this to only grab the table we are interested in
        # use BeautifulSoup to parse through the html
        soup = BeautifulSoup(req.text, "html.parser")

        # find all the tables that fit these attributes
        # we only want the ExploitDB/CVENum table, so we index with [1] to grab table #2
        table = soup.findAll("table", attrs={"cellpadding": "2", "cellspacing": "2", "border": "2"})[1]

        # The first tr contains the field names.
        headings = ["ExploitId", "CveId"]
        datasets = []

        for row in table.find_all("tr")[0:]:
            row = list(td.get_text() for td in row.find_all("td"))
            # print(type(dataset))
            # df.append(dataset, ignore_index = True)
            # df = pd.DataFrame(dataset, columns=['ExploitDB Number', 'CVE Number'])
            datasets.append(row)
            # print(dataset)

        df = pd.DataFrame(datasets,
                          columns=headings)  # creating data frame with the proper headings and loading in the data
        df = df.astype('string')  # converting the pandas objects (default) to strings
        df.drop(df.tail(2).index, inplace=True)  # dropping the last two rows because they don't have exploit db Id's
        df[headings[0]] = df[headings[0]].str.replace(r'\D',
                                                      '')  # removing the prefix "EXPLOIT-DB" from the ExploitDBId column
        df[headings[1]] = df[headings[1]].str.rstrip("\n")  # removing the trailing newline from the CVEId column
        df[headings[1]] = df[headings[1]].str.lstrip(' ')  # removing the leading white space from the CVEId column
        df[headings[1]] = df[headings[1]].str.split(' ')  # splitting the column based on white space within the entries
        df = df.set_index([headings[0]])[headings[1]].apply(pd.Series).stack().reset_index().drop('level_1',
                                                                                                  axis=1).rename(
            columns={0: headings[1]})  # creating multiple rows for exploits that correspond to multiple CVE #'s

        n = len(df[headings[1]])  # find the number of rows in the dataframe
        csv_writer.writerow(headings)
        for i in range(n - 1):
            csv_writer.writerow(df.loc[i])  # writing data frame to a csv file

        csv_file.close()

        df.to_json(self.cve_to_explot_file, indent=2, orient='records')  # writing the dataframe to a json file



if __name__ == '__main__':
    v = VulnerabilityMapper()
    cves = v.cpe_to_cve('cpe:/a:proftpd:proftpd:1.3.1')
    print(cves)
    for c in cves:
        print(v.cve_to_exploits(c))

